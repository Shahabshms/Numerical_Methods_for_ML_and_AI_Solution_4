{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " -- 4301 -- HW4 -- Q2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUZeiUjS2iJOtnwWiLPuxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahabshms/Numerical_Methods_for_ML_and_AI_Solution_4/blob/main/_4301_HW4_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhNHqsZUW2UC"
      },
      "source": [
        "3. Write a Python function that takes as input the matrices $A$ and $Q$, an initial guess for the completion, $B$, and a number of iterations and returns the the result of applying projected\n",
        "gradient descent, starting at $B$, for the specified number of iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZcw5EhnXG1K"
      },
      "source": [
        "The goal here is to minimize function\n",
        "\\begin{align*}\n",
        "    g(B) = \\frac{1}{2} \\sum_{\\substack{i,j\\in\\{1,\\dots,n\\}\\\\ Q_{i,j}=0}} (A_{i,j} - B_{i,j})^2\n",
        "\\end{align*}\n",
        "such that $$B\\succeq 0.$$\n",
        "\n",
        "\n",
        "So, for all $i,j\\in\\{1,\\dots,n\\}$, we have\n",
        "\\begin{align*}\n",
        "\\cfrac{\\partial g(B)}{\\partial B_{i,j}} = \\left\\{\n",
        "\\begin{array}{l,l}\n",
        " -(A_{i,j} - B_{i,j})\n",
        "&\\text{if } Q_{i,j} = 0,\\\\\n",
        "\\cfrac{\\partial g(B)}{\\partial B_{j,i}} & \\text{if } Q_{i,j} = 1 \\text{and }Q_{j,i} = 0,\\\\\n",
        "0 & \\text{if } Q_{i,j} = 1 \\text{and } Q_{j,i} = 1.\n",
        "\\end{array}\\right.\n",
        "\\end{align*}\n",
        "And in the following function, the gradient will be constructed based on these derivatives. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auB_mM68RfSZ"
      },
      "source": [
        "def get_gradient(B,A,Q):\n",
        "  gradient = np.zeros([B.shape[0],B.shape[0]])\n",
        "  for i,j in itertools.product(range(B.shape[0]),range(B.shape[0])):\n",
        "    if Q[i,j] == 0:\n",
        "      gradient[i,j] = B[i,j] - A[i,j]\n",
        "      if Q[j,i] == 1:\n",
        "        gradient[j,i] = gradient[i,j]\n",
        "  return gradient\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OajOqMTX-6s"
      },
      "source": [
        "As always, in each iteration of the gradient descent, we need to update our variables. So\n",
        "$$B^{\\text{new}} = B^{\\text{old}} - \\eta \\nabla_B g(B)$$\n",
        "But we have to make sure that at each time, $B^{new}$ remains positive semidefinte. This is why we need to implement Projected Gradient Descent. The next function is responsible for getting $B^{\\text{new}}$ and project it into the convex set of positive semidefinite matrices.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ABvuzQVrn3"
      },
      "source": [
        "def projection(B):\n",
        "  eig_vals, eig_vecs = np.linalg.eig(B)\n",
        "  eig_vals[eig_vals < 0] = 0\n",
        "  B = eig_vecs*np.diag(eig_vals)*np.transpose(eig_vecs)\n",
        "  return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVBjhsUAcG49"
      },
      "source": [
        "And, the final function is the Projected Gradient Descent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj3_f2_hcB8B"
      },
      "source": [
        "def projected_gradient_descent(initial_B,original_matrix,Q,max_iterations):\n",
        "  B = initial_B\n",
        "  A = original_matrix\n",
        "\n",
        "  for iteration in range(max_iterations):\n",
        "    nu = 2 / (2 + iteration) # step size of choice. It is better that you try different step sizes. \n",
        "\n",
        "    gradient = get_gradient(B,A,Q)\n",
        "    B = B - nu * gradient # Update B. \n",
        "    B = projection(B)\n",
        "\n",
        "  return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92EzanfabdfS"
      },
      "source": [
        "Notice that the proble is convex. So changing the initial point must not change the final answer, as long as the initial point is positive semidefinite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEBn47FbWHJL",
        "outputId": "1636e0ca-5549-4201-a591-ce9185914377"
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "A = np.matrix([[1,0,80],[1,0,0],[None,None,5]])\n",
        "initial_B = np.matrix([[1,0,8],[0,5,6],[1,2,3]])\n",
        "Q = (A == None) + 0\n",
        "B = projected_gradient_descent(initial_B,A,Q,100)\n",
        "print(A,'\\n')\n",
        "\n",
        "\n",
        "print(B,'\\n')\n",
        "print(np.linalg.eigvals(B),'\\n-------')\n",
        "\n",
        "initial_B = np.matrix([[1,0,0],[4,5,6],[1,0,9]])\n",
        "B = projected_gradient_descent(initial_B,A,Q,100)\n",
        "print(B,'\\n')\n",
        "print(np.linalg.eigvals(B))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 80]\n",
            " [1 0 0]\n",
            " [None None 5]] \n",
            "\n",
            "[[4.04717961e+01 4.87474668e-01 4.14962358e+01]\n",
            " [4.87474668e-01 5.88319468e-03 4.99813839e-01]\n",
            " [4.14962358e+01 4.99813839e-01 4.25466066e+01]] \n",
            "\n",
            "[ 8.30242742e+01 -4.18592163e-15  1.16592410e-05] \n",
            "-------\n",
            "[[4.04721920e+01 4.87470003e-01 4.14966425e+01]\n",
            " [4.87470003e-01 5.88593821e-03 4.99809065e-01]\n",
            " [4.14966425e+01 4.99809065e-01 4.25470243e+01]] \n",
            "\n",
            "[8.30250876e+01 1.42516004e-15 1.45723674e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}